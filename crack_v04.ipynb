{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsOPVfLwTW-r"
      },
      "source": [
        "# Nuova sezione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-algX0_HPie",
        "outputId": "32715b74-eddf-40fe-ff26-1be57c3e611d"
      },
      "source": [
        "#Download dataset\n",
        "\n",
        "!wget  https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/5y9wdsg2zt-1.zip -O Crack_dataset.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-14 17:47:16--  https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/5y9wdsg2zt-1.zip\n",
            "Resolving md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)... 52.218.36.43\n",
            "Connecting to md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)|52.218.36.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 240847944 (230M) [application/octet-stream]\n",
            "Saving to: ‘Crack_dataset.zip’\n",
            "\n",
            "Crack_dataset.zip   100%[===================>] 229.69M  32.6MB/s    in 7.9s    \n",
            "\n",
            "2021-05-14 17:47:24 (29.0 MB/s) - ‘Crack_dataset.zip’ saved [240847944/240847944]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBHA2xPbJDFn",
        "outputId": "e7444b1a-8ddd-45a0-e8c2-2af8ef27f10b"
      },
      "source": [
        " #Unzip dataset\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/Crack_dataset.zip\"\n",
        "\n",
        "with ZipFile(file_name, \"r\") as zip:\n",
        "  zip.extractall()\n",
        "  \n",
        "\n",
        "!unrar x Concrete\\ Crack\\ Images\\ for\\ Classification.rar -inul\n",
        "print(\"done\")\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ1au0M_MYXm",
        "outputId": "8dfd9bda-b40d-42b7-dd5b-608872a9f319"
      },
      "source": [
        "!mkdir Dataset\n",
        "!mv Negative Dataset/Non-Cracked\n",
        "!mv Positive Dataset/Cracked\n",
        "!rm Crack_dataset.zip\n",
        "!rm Concrete\\ Crack\\ Images\\ for\\ Classification.rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Dataset’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ0Xep1AS7Vp",
        "outputId": "5011da47-fe7d-4eeb-c9f5-773703b605ac"
      },
      "source": [
        "import os\n",
        "print(f\"Cracked: {len(os.listdir('Dataset/Cracked'))}\")\n",
        "print(f\"Non-cracked: {len(os.listdir('Dataset/Non-Cracked'))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cracked: 20001\n",
            "Non-cracked: 20001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UEasInQU6mL"
      },
      "source": [
        "#load deck dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "dataset = ImageFolder(\"Dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hngOJ6PvR3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87afc091-5013-49c2-a659-6f2c2078806c"
      },
      "source": [
        "#check\n",
        "from collections import Counter\n",
        "print(dataset)\n",
        "print(dataset.imgs)\n",
        "print(dataset.classes)\n",
        "print(Counter(dataset.targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZECg6-w0H-f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(dataset.imgs, dataset.targets, test_size=0.2, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWIkD8Aj4zAQ"
      },
      "source": [
        "from torchvision import transforms\n",
        "transform = transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Normalize([0.5] * 3, [0.5] * 3)  #[0.5, 0.5, 0.5]                           \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bSCxpmG4u9l"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class ImageLoader(Dataset):\n",
        "  def __init__(self, dataset, transform=None):\n",
        "    self.dataset = dataset\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    image = Image.open(self.dataset[item][0])\n",
        "    if self.transform is not None:\n",
        "      return self.transform(image), self.dataset[item][1]\n",
        "    return image, self.dataset[item][1]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def checkRGB(self, dataset):\n",
        "    datasetRGB = []\n",
        "    for index in range(len(dataset)):\n",
        "      if Image.open(dataset[index][0]).getbands != (\"R\", \"G\", \"B\"):\n",
        "        datasetRGB.append(dataset[index])\n",
        "    return datasetRGB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4nS9I4n4DBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecfad3c-7507-4e7b-b5d0-ae33d9d83041"
      },
      "source": [
        "#check\n",
        "img_loader = ImageLoader(train_data)\n",
        "if len(train_data) == len(img_loader.checkRGB(train_data)):\n",
        "  print(\"all images are RGB\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all images are RGB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMB8lBQr7sAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe9cfe5-68c2-4746-8ec5-cbdb3824caf1"
      },
      "source": [
        "#check\n",
        "img_loader = ImageLoader(train_data, transform)\n",
        "print(img_loader[0][0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 227, 227])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0OY4WXRDAU2"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 10\n",
        "train_loader = DataLoader(ImageLoader(train_data, transform), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(ImageLoader(test_data, transform), batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hwgUIFNEyq4"
      },
      "source": [
        "#network definition\n",
        "from torch.nn import Module, Conv2d, Linear, MaxPool2d, AdaptiveAvgPool1d\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "class Network(Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1 = Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "    self.conv2 = Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.conv3 = Conv2d(in_channels=128, out_channels=256, kernel_size=5)\n",
        "\n",
        "    self.pool = MaxPool2d(kernel_size=4)\n",
        "    self.AAPooling = AdaptiveAvgPool1d(256)\n",
        "\n",
        "    self.fc1 = Linear(in_features=256, out_features=128)\n",
        "    self.fc2 = Linear(in_features=128, out_features=64)\n",
        "    self.out = Linear(in_features=64, out_features=2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(relu(self.conv1(x)))\n",
        "    x = self.pool(relu(self.conv2(x)))\n",
        "    x = self.pool(relu(self.conv3(x)))\n",
        "    \n",
        "    \n",
        "    x = x.view(1, x.size()[0], -1)\n",
        "    x = self.AAPooling(x).squeeze()\n",
        "    \n",
        "\n",
        "    x = relu(self.fc1(x))\n",
        "    x = relu(self.fc2(x))\n",
        "\n",
        "    \n",
        "    return self.out(x)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHm8KYUTIhie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e1d966-5465-45f5-b753-89ff0ed1c73f"
      },
      "source": [
        "#check\n",
        "sample_data = iter(train_loader)\n",
        "sample_images = next(sample_data)\n",
        "\n",
        "net = Network()\n",
        "out = net(sample_images[0])\n",
        "print(out)\n",
        "sample_images[1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0807, -0.0362],\n",
            "        [ 0.0747, -0.0387],\n",
            "        [ 0.0824, -0.0338],\n",
            "        [ 0.0798, -0.0350],\n",
            "        [ 0.0742, -0.0382],\n",
            "        [ 0.0741, -0.0381],\n",
            "        [ 0.0814, -0.0346],\n",
            "        [ 0.0799, -0.0367],\n",
            "        [ 0.0761, -0.0380],\n",
            "        [ 0.0803, -0.0357]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsLDRz0kdnQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46080b54-fc15-46b3-e12b-185d217e9d81"
      },
      "source": [
        "#Training\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_epochs = 3\n",
        "#batch_size = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "#class_weights = torch.tensor([0.85, 0.15]).to(device)\n",
        "\n",
        "from torch.nn import CrossEntropyLoss, BCELoss\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 1000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Step [100/6400], Loss: 0.6720\n",
            "Epoch [1/3], Step [200/6400], Loss: 0.6814\n",
            "Epoch [1/3], Step [300/6400], Loss: 0.7086\n",
            "Epoch [1/3], Step [400/6400], Loss: 0.6969\n",
            "Epoch [1/3], Step [500/6400], Loss: 0.6792\n",
            "Epoch [1/3], Step [600/6400], Loss: 0.6851\n",
            "Epoch [1/3], Step [700/6400], Loss: 0.6921\n",
            "Epoch [1/3], Step [800/6400], Loss: 0.6908\n",
            "Epoch [1/3], Step [900/6400], Loss: 0.6882\n",
            "Epoch [1/3], Step [1000/6400], Loss: 0.6725\n",
            "Epoch [1/3], Step [1100/6400], Loss: 0.6591\n",
            "Epoch [1/3], Step [1200/6400], Loss: 0.6727\n",
            "Epoch [1/3], Step [1300/6400], Loss: 0.6667\n",
            "Epoch [1/3], Step [1400/6400], Loss: 0.6682\n",
            "Epoch [1/3], Step [1500/6400], Loss: 0.6549\n",
            "Epoch [1/3], Step [1600/6400], Loss: 0.6767\n",
            "Epoch [1/3], Step [1700/6400], Loss: 0.6659\n",
            "Epoch [1/3], Step [1800/6400], Loss: 0.6629\n",
            "Epoch [1/3], Step [1900/6400], Loss: 0.6663\n",
            "Epoch [1/3], Step [2000/6400], Loss: 0.6717\n",
            "Epoch [1/3], Step [2100/6400], Loss: 0.6598\n",
            "Epoch [1/3], Step [2200/6400], Loss: 0.6582\n",
            "Epoch [1/3], Step [2300/6400], Loss: 0.6108\n",
            "Epoch [1/3], Step [2400/6400], Loss: 0.6297\n",
            "Epoch [1/3], Step [2500/6400], Loss: 0.6389\n",
            "Epoch [1/3], Step [2600/6400], Loss: 0.6193\n",
            "Epoch [1/3], Step [2700/6400], Loss: 0.5860\n",
            "Epoch [1/3], Step [2800/6400], Loss: 0.5078\n",
            "Epoch [1/3], Step [2900/6400], Loss: 0.5491\n",
            "Epoch [1/3], Step [3000/6400], Loss: 0.5773\n",
            "Epoch [1/3], Step [3100/6400], Loss: 0.5234\n",
            "Epoch [1/3], Step [3200/6400], Loss: 0.4946\n",
            "Epoch [1/3], Step [3300/6400], Loss: 0.3756\n",
            "Epoch [1/3], Step [3400/6400], Loss: 0.2594\n",
            "Epoch [1/3], Step [3500/6400], Loss: 0.3637\n",
            "Epoch [1/3], Step [3600/6400], Loss: 0.5060\n",
            "Epoch [1/3], Step [3700/6400], Loss: 0.3587\n",
            "Epoch [1/3], Step [3800/6400], Loss: 0.3354\n",
            "Epoch [1/3], Step [3900/6400], Loss: 0.2214\n",
            "Epoch [1/3], Step [4000/6400], Loss: 0.1301\n",
            "Epoch [1/3], Step [4100/6400], Loss: 0.5070\n",
            "Epoch [1/3], Step [4200/6400], Loss: 0.0886\n",
            "Epoch [1/3], Step [4300/6400], Loss: 0.1517\n",
            "Epoch [1/3], Step [4400/6400], Loss: 0.1414\n",
            "Epoch [1/3], Step [4500/6400], Loss: 0.1947\n",
            "Epoch [1/3], Step [4600/6400], Loss: 0.2696\n",
            "Epoch [1/3], Step [4700/6400], Loss: 0.2596\n",
            "Epoch [1/3], Step [4800/6400], Loss: 0.0689\n",
            "Epoch [1/3], Step [4900/6400], Loss: 0.0679\n",
            "Epoch [1/3], Step [5000/6400], Loss: 0.0406\n",
            "Epoch [1/3], Step [5100/6400], Loss: 0.2250\n",
            "Epoch [1/3], Step [5200/6400], Loss: 0.0636\n",
            "Epoch [1/3], Step [5300/6400], Loss: 0.0884\n",
            "Epoch [1/3], Step [5400/6400], Loss: 0.0481\n",
            "Epoch [1/3], Step [5500/6400], Loss: 0.4165\n",
            "Epoch [1/3], Step [5600/6400], Loss: 0.0485\n",
            "Epoch [1/3], Step [5700/6400], Loss: 0.2642\n",
            "Epoch [1/3], Step [5800/6400], Loss: 0.1605\n",
            "Epoch [1/3], Step [5900/6400], Loss: 0.3703\n",
            "Epoch [1/3], Step [6000/6400], Loss: 0.0849\n",
            "Epoch [1/3], Step [6100/6400], Loss: 0.2531\n",
            "Epoch [1/3], Step [6200/6400], Loss: 0.4678\n",
            "Epoch [1/3], Step [6300/6400], Loss: 0.0266\n",
            "Epoch [1/3], Step [6400/6400], Loss: 0.0389\n",
            "Epoch [2/3], Step [100/6400], Loss: 0.2021\n",
            "Epoch [2/3], Step [200/6400], Loss: 0.1342\n",
            "Epoch [2/3], Step [300/6400], Loss: 0.0322\n",
            "Epoch [2/3], Step [400/6400], Loss: 0.6131\n",
            "Epoch [2/3], Step [500/6400], Loss: 0.4862\n",
            "Epoch [2/3], Step [600/6400], Loss: 0.0396\n",
            "Epoch [2/3], Step [700/6400], Loss: 0.0658\n",
            "Epoch [2/3], Step [800/6400], Loss: 0.0411\n",
            "Epoch [2/3], Step [900/6400], Loss: 0.5960\n",
            "Epoch [2/3], Step [1000/6400], Loss: 0.0564\n",
            "Epoch [2/3], Step [1100/6400], Loss: 0.2137\n",
            "Epoch [2/3], Step [1200/6400], Loss: 0.0571\n",
            "Epoch [2/3], Step [1300/6400], Loss: 0.3397\n",
            "Epoch [2/3], Step [1400/6400], Loss: 0.1138\n",
            "Epoch [2/3], Step [1500/6400], Loss: 0.0214\n",
            "Epoch [2/3], Step [1600/6400], Loss: 0.1464\n",
            "Epoch [2/3], Step [1700/6400], Loss: 0.0580\n",
            "Epoch [2/3], Step [1800/6400], Loss: 0.0401\n",
            "Epoch [2/3], Step [1900/6400], Loss: 0.0501\n",
            "Epoch [2/3], Step [2000/6400], Loss: 0.0320\n",
            "Epoch [2/3], Step [2100/6400], Loss: 0.0290\n",
            "Epoch [2/3], Step [2200/6400], Loss: 0.0222\n",
            "Epoch [2/3], Step [2300/6400], Loss: 0.2267\n",
            "Epoch [2/3], Step [2400/6400], Loss: 0.0258\n",
            "Epoch [2/3], Step [2500/6400], Loss: 0.4892\n",
            "Epoch [2/3], Step [2600/6400], Loss: 0.3552\n",
            "Epoch [2/3], Step [2700/6400], Loss: 0.0162\n",
            "Epoch [2/3], Step [2800/6400], Loss: 0.3800\n",
            "Epoch [2/3], Step [2900/6400], Loss: 0.1433\n",
            "Epoch [2/3], Step [3000/6400], Loss: 0.1355\n",
            "Epoch [2/3], Step [3100/6400], Loss: 0.0213\n",
            "Epoch [2/3], Step [3200/6400], Loss: 0.0144\n",
            "Epoch [2/3], Step [3300/6400], Loss: 0.0237\n",
            "Epoch [2/3], Step [3400/6400], Loss: 0.0866\n",
            "Epoch [2/3], Step [3500/6400], Loss: 0.1572\n",
            "Epoch [2/3], Step [3600/6400], Loss: 0.0416\n",
            "Epoch [2/3], Step [3700/6400], Loss: 0.0142\n",
            "Epoch [2/3], Step [3800/6400], Loss: 0.1621\n",
            "Epoch [2/3], Step [3900/6400], Loss: 0.0610\n",
            "Epoch [2/3], Step [4000/6400], Loss: 0.0317\n",
            "Epoch [2/3], Step [4100/6400], Loss: 0.1875\n",
            "Epoch [2/3], Step [4200/6400], Loss: 0.0414\n",
            "Epoch [2/3], Step [4300/6400], Loss: 0.2197\n",
            "Epoch [2/3], Step [4400/6400], Loss: 0.1193\n",
            "Epoch [2/3], Step [4500/6400], Loss: 0.0434\n",
            "Epoch [2/3], Step [4600/6400], Loss: 0.0180\n",
            "Epoch [2/3], Step [4700/6400], Loss: 0.1853\n",
            "Epoch [2/3], Step [4800/6400], Loss: 0.0465\n",
            "Epoch [2/3], Step [4900/6400], Loss: 0.1894\n",
            "Epoch [2/3], Step [5000/6400], Loss: 0.0110\n",
            "Epoch [2/3], Step [5100/6400], Loss: 0.1859\n",
            "Epoch [2/3], Step [5200/6400], Loss: 0.0167\n",
            "Epoch [2/3], Step [5300/6400], Loss: 0.3843\n",
            "Epoch [2/3], Step [5400/6400], Loss: 0.0622\n",
            "Epoch [2/3], Step [5500/6400], Loss: 0.0222\n",
            "Epoch [2/3], Step [5600/6400], Loss: 0.0286\n",
            "Epoch [2/3], Step [5700/6400], Loss: 0.4134\n",
            "Epoch [2/3], Step [5800/6400], Loss: 0.2385\n",
            "Epoch [2/3], Step [5900/6400], Loss: 0.3256\n",
            "Epoch [2/3], Step [6000/6400], Loss: 0.0379\n",
            "Epoch [2/3], Step [6100/6400], Loss: 0.1014\n",
            "Epoch [2/3], Step [6200/6400], Loss: 0.0213\n",
            "Epoch [2/3], Step [6300/6400], Loss: 0.1826\n",
            "Epoch [2/3], Step [6400/6400], Loss: 0.0631\n",
            "Epoch [3/3], Step [100/6400], Loss: 0.2299\n",
            "Epoch [3/3], Step [200/6400], Loss: 0.0153\n",
            "Epoch [3/3], Step [300/6400], Loss: 0.3424\n",
            "Epoch [3/3], Step [400/6400], Loss: 0.0250\n",
            "Epoch [3/3], Step [500/6400], Loss: 0.1195\n",
            "Epoch [3/3], Step [600/6400], Loss: 0.0167\n",
            "Epoch [3/3], Step [700/6400], Loss: 0.0265\n",
            "Epoch [3/3], Step [800/6400], Loss: 0.0209\n",
            "Epoch [3/3], Step [900/6400], Loss: 0.1649\n",
            "Epoch [3/3], Step [1000/6400], Loss: 0.2529\n",
            "Epoch [3/3], Step [1100/6400], Loss: 0.0339\n",
            "Epoch [3/3], Step [1200/6400], Loss: 0.0117\n",
            "Epoch [3/3], Step [1300/6400], Loss: 0.0110\n",
            "Epoch [3/3], Step [1400/6400], Loss: 0.0107\n",
            "Epoch [3/3], Step [1500/6400], Loss: 0.0078\n",
            "Epoch [3/3], Step [1600/6400], Loss: 0.0324\n",
            "Epoch [3/3], Step [1700/6400], Loss: 0.0327\n",
            "Epoch [3/3], Step [1800/6400], Loss: 0.1478\n",
            "Epoch [3/3], Step [1900/6400], Loss: 0.0241\n",
            "Epoch [3/3], Step [2000/6400], Loss: 0.0759\n",
            "Epoch [3/3], Step [2100/6400], Loss: 0.1226\n",
            "Epoch [3/3], Step [2200/6400], Loss: 0.0946\n",
            "Epoch [3/3], Step [2300/6400], Loss: 0.0181\n",
            "Epoch [3/3], Step [2400/6400], Loss: 0.0123\n",
            "Epoch [3/3], Step [2500/6400], Loss: 0.0416\n",
            "Epoch [3/3], Step [2600/6400], Loss: 0.1926\n",
            "Epoch [3/3], Step [2700/6400], Loss: 0.0162\n",
            "Epoch [3/3], Step [2800/6400], Loss: 0.1328\n",
            "Epoch [3/3], Step [2900/6400], Loss: 0.0208\n",
            "Epoch [3/3], Step [3000/6400], Loss: 0.0443\n",
            "Epoch [3/3], Step [3100/6400], Loss: 0.0288\n",
            "Epoch [3/3], Step [3200/6400], Loss: 0.0262\n",
            "Epoch [3/3], Step [3300/6400], Loss: 0.0423\n",
            "Epoch [3/3], Step [3400/6400], Loss: 0.0382\n",
            "Epoch [3/3], Step [3500/6400], Loss: 0.3078\n",
            "Epoch [3/3], Step [3600/6400], Loss: 0.0239\n",
            "Epoch [3/3], Step [3700/6400], Loss: 0.2417\n",
            "Epoch [3/3], Step [3800/6400], Loss: 0.0110\n",
            "Epoch [3/3], Step [3900/6400], Loss: 0.0143\n",
            "Epoch [3/3], Step [4000/6400], Loss: 0.0962\n",
            "Epoch [3/3], Step [4100/6400], Loss: 0.0121\n",
            "Epoch [3/3], Step [4200/6400], Loss: 0.1738\n",
            "Epoch [3/3], Step [4300/6400], Loss: 0.0191\n",
            "Epoch [3/3], Step [4400/6400], Loss: 0.0309\n",
            "Epoch [3/3], Step [4500/6400], Loss: 0.0208\n",
            "Epoch [3/3], Step [4600/6400], Loss: 0.0096\n",
            "Epoch [3/3], Step [4700/6400], Loss: 0.0214\n",
            "Epoch [3/3], Step [4800/6400], Loss: 0.1058\n",
            "Epoch [3/3], Step [4900/6400], Loss: 0.0901\n",
            "Epoch [3/3], Step [5000/6400], Loss: 0.0257\n",
            "Epoch [3/3], Step [5100/6400], Loss: 0.0213\n",
            "Epoch [3/3], Step [5200/6400], Loss: 0.0235\n",
            "Epoch [3/3], Step [5300/6400], Loss: 0.0120\n",
            "Epoch [3/3], Step [5400/6400], Loss: 0.0240\n",
            "Epoch [3/3], Step [5500/6400], Loss: 0.0330\n",
            "Epoch [3/3], Step [5600/6400], Loss: 0.1106\n",
            "Epoch [3/3], Step [5700/6400], Loss: 0.0175\n",
            "Epoch [3/3], Step [5800/6400], Loss: 0.0478\n",
            "Epoch [3/3], Step [5900/6400], Loss: 0.0108\n",
            "Epoch [3/3], Step [6000/6400], Loss: 0.0114\n",
            "Epoch [3/3], Step [6100/6400], Loss: 0.0489\n",
            "Epoch [3/3], Step [6200/6400], Loss: 0.0471\n",
            "Epoch [3/3], Step [6300/6400], Loss: 0.0083\n",
            "Epoch [3/3], Step [6400/6400], Loss: 0.0610\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJHiywg6iVdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4561aacb-e285-4609-c28e-b9c6948064df"
      },
      "source": [
        "#testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(2)]\n",
        "    n_class_samples = [0 for i in range(2)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(2):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    classes ={1:\"Uncracked\", 0:\"Cracked\"}\n",
        "    for i in range(2):\n",
        "       acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "       print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network: 97.9625 %\n",
            "Accuracy of Cracked: 98.64615384615385 %\n",
            "Accuracy of Uncracked: 97.01587301587301 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r14BOrV0dGK"
      },
      "source": [
        "#testing for overfitting\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(2)]\n",
        "    n_class_samples = [0 for i in range(2)]\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(2):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    classes ={1:\"Uncracked\", 0:\"Cracked\"}\n",
        "    for i in range(2):\n",
        "       acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "       print(f'Accuracy of {classes[i]}: {acc} %')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}